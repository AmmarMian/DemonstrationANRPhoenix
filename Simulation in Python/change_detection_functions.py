##############################################################################
# Functions used to detect a change in the parameters of a SIRV distribution
# Authored by Ammar Mian, 28/09/2018
# e-mail: ammar.mian@centralesupelec.fr
##############################################################################
# Copyright 2018 @CentraleSupelec
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##############################################################################
import numpy as np
import scipy as sp
import warnings
from generic_functions import *

##############################################################################
# Gaussian Statistics
##############################################################################
def covariance_equality_glrt_gaussian_statistic(ğ—, *args):
    """ GLRT statistic for detecting a change of covariance matrix in a multivariate Gaussian Time Series.
        At each time, Ni.i.d samples are available. A description of the statistic can be found in:
        D. Ciuonzo, V. Carotenuto and A. De Maio, 
        "On Multiple Covariance Equality Testing with Application to SAR Change Detection," 
        in IEEE Transactions on Signal Processing, vol. 65, no. 19, pp. 5078-5091, 1 Oct.1, 2017.
        doi: 10.1109/TSP.2017.2712124
        Inputs:
            * ğ— = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
        Outputs:
            * the GLRT statistic given the observations in input"""

    (p, N, T) = ğ—.shape
    S = 0
    logDenominator = 0
    for t in range(0, T):
        St = SCM(ğ—[:, :, t])
        logDenominator = logDenominator + N * np.log(np.abs(np.linalg.det(St)))
        S = S + St / T
    logNumerator = N * T * np.log(np.abs(np.linalg.det(S)))
    return np.exp(logNumerator - logDenominator)


def covariance_equality_t1_gaussian_statistic(ğ—, *args):
    """ t1 statistic for detecting a change of covariance matrix in a multivariate Gaussian Time Series.
        At each time, Ni.i.d samples are available. A description of the statistic can be found in:
        D. Ciuonzo, V. Carotenuto and A. De Maio, 
        "On Multiple Covariance Equality Testing with Application to SAR Change Detection," 
        in IEEE Transactions on Signal Processing, vol. 65, no. 19, pp. 5078-5091, 1 Oct.1, 2017.
        doi: 10.1109/TSP.2017.2712124
        Inputs:
            * ğ— = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
        Outputs:
            * the t1 statistic given the observations in input"""

    (N, K, M) = ğ—.shape

    Sigma_10 = SCM(ğ—.reshape((N, K*M)))
    iSigma_10 = np.linalg.inv(Sigma_10)
    t1 = 0
    for t in range(0, M):
        Sigma_m1 = SCM(ğ—[:, :, t])
        S = (iSigma_10 @ Sigma_m1)
        t1 = t1 + np.trace( S @ S )/M;
    return np.real(t1)


def covariance_equality_Wald_gaussian_statistic(ğ—, *args):
    """ Wald statistic for detecting a change of covariance matrix in a multivariate Gaussian Time Series.
        At each time, Ni.i.d samples are available. A description of the statistic can be found in:
        D. Ciuonzo, V. Carotenuto and A. De Maio, 
        "On Multiple Covariance Equality Testing with Application to SAR Change Detection," 
        in IEEE Transactions on Signal Processing, vol. 65, no. 19, pp. 5078-5091, 1 Oct.1, 2017.
        doi: 10.1109/TSP.2017.2712124
        Inputs:
            * ğ— = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
        Outputs:
            * the Wald statistic given the observations in input"""

    (N, K, M) = ğ—.shape
    L = 0;
    O = 0;
    Q = 0;
    Sigma_11 = SCM(ğ—[:, :, 0])
    for m in range(0,M):
        Sigma_m1 = SCM(ğ—[:, :, m])
        iSigma_m1 = np.linalg.inv(Sigma_m1)
        if m != 0:
            S = np.eye(N) - Sigma_11@iSigma_m1
            L = L + K*np.trace(S@S)
            Q = Q + K*(iSigma_m1 - iSigma_m1@Sigma_11@iSigma_m1)
        O = O + K*np.kron(iSigma_m1.T, iSigma_m1)
    
    return np.real(L - vec(Q).conj().T @ (np.linalg.inv(O)@vec(Q)))[0,0]


##############################################################################
# Robust Statistics
##############################################################################
def scale_and_shape_equality_robust_statistic(ğ—, args):
    """ GLRT test for testing a change in the scale or/and shape in 
        a deterministic SIRV model.
        Inputs:
            * ğ— = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
            * args = tol, iter_max for Tyler
        Outputs:
            * the statistic given the observations in input"""

    tol, iter_max = args
    (p, N, T) = ğ—.shape

    # Estimating ğšº_0 using all the observations
    (ğšº_0, Î´, niter) = tyler_estimator_covariance_matandtext(ğ—, tol, iter_max)
    iğšº_0 = np.linalg.inv(ğšº_0)

    # Some initialisation
    log_numerator_determinant_terms = T*N*np.log(np.abs(np.linalg.det(ğšº_0)))
    log_denominator_determinant_terms = 0
    ğ›•_0 = 0
    logğ›•_t = 0
    # Iterating on each date to compute the needed terms
    for t in range(0,T):
        # Estimating ğšº_t
        (ğšº_t, Î´, iteration) = tyler_estimator_covariance(ğ—[:,:,t], tol, iter_max)

        # Computing determinant add adding it to log_denominator_determinant_terms
        log_denominator_determinant_terms = log_denominator_determinant_terms + \
                                            N*np.log(np.abs(np.linalg.det(ğšº_t)))

        # Computing texture estimation
        ğ›•_0 =  ğ›•_0 + np.diagonal(ğ—[:,:,t].conj().T@iğšº_0@ğ—[:,:,t]) / T
        logğ›•_t = logğ›•_t + np.log(np.diagonal(ğ—[:,:,t].conj().T@np.linalg.inv(ğšº_t)@ğ—[:,:,t]))

    # Computing quadratic terms
    log_numerator_quadtratic_terms = T*p*np.sum(np.log(ğ›•_0))
    log_denominator_quadtratic_terms = p*np.sum(logğ›•_t)

    # Final expression of the statistic
    Î» = np.exp(np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms))

    return Î»

def shape_equality_robust_statistic(ğ—, args):
    """ GLRT test for testing a change in the shape in 
        a deterministic SIRV model.
        Inputs:
            * ğ— = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
            * args = tol, iter_max for Tyler
        Outputs:
            * the statistic given the observations in input"""

    tol, iter_max = args
    (p, N, T) = ğ—.shape

    # Estimating ğšº_0 using all the observations
    (ğšº_0, Î´, niter) = tyler_estimator_covariance(ğ—.reshape((p,T*N)), tol, iter_max)
    iğšº_0 = np.linalg.inv(ğšº_0)

    # Some initialisation
    log_numerator_determinant_terms = T*N*np.log(np.abs(np.linalg.det(ğšº_0)))
    log_denominator_determinant_terms = 0
    logğ›•_0 = 0
    logğ›•_t = 0
    # Iterating on each date to compute the needed terms
    for t in range(0,T):
        # Estimating ğšº_t
        (ğšº_t, Î´, iteration) = tyler_estimator_covariance(ğ—[:,:,t], tol, iter_max)

        # Computing determinant add adding it to log_denominator_determinant_terms
        log_denominator_determinant_terms = log_denominator_determinant_terms + \
                                            N*np.log(np.abs(np.linalg.det(ğšº_t)))

        # Computing texture estimation
        logğ›•_0 =  logğ›•_0 + np.log(np.diagonal(ğ—[:,:,t].conj().T@iğšº_0@ğ—[:,:,t]))
        logğ›•_t = logğ›•_t + np.log(np.diagonal(ğ—[:,:,t].conj().T@np.linalg.inv(ğšº_t)@ğ—[:,:,t]))

    # Computing quadratic terms
    log_numerator_quadtratic_terms = p*np.sum(logğ›•_0)
    log_denominator_quadtratic_terms = p*np.sum(logğ›•_t)

    # Final expression of the statistic
    Î» = np.exp(np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms))

    return Î»


def scale_equality_robust_statistic(ğ—, args):
    """ GLRT test for testing a change in the scale in 
        a deterministic SIRV model.
        Inputs:
            * ğ— = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
            * args = tol, iter_max for Tyler
        Outputs:
            * the statistic given the observations in input"""

    tol, iter_max = args
    (p, N, T) = ğ—.shape

    # Estimating ğšº_t under H0 regime using all the observations
    (ğšº_0, ğ›…, niter) = tyler_estimator_covariance_text(ğ—, tol, iter_max)

    # Some initialisation
    log_numerator_determinant_terms = 0
    log_denominator_determinant_terms = 0
    ğ›•_0 = 0
    logğ›•_t = 0
    # Iterating on each date to compute the needed terms
    for t in range(0,T):

        # Estimating ğšº_t under H1 regime
        (ğšº_t, Î´, iteration) = tyler_estimator_covariance(ğ—[:,:,t], tol, iter_max)

        # Computing determinant add adding it to log_numerator_determinant_terms
        log_numerator_determinant_terms = log_numerator_determinant_terms + \
                                        N*np.log(np.abs(np.linalg.det(ğšº_0[:,:,t])))

        # Computing determinant add adding it to log_denominator_determinant_terms
        log_denominator_determinant_terms = log_denominator_determinant_terms + \
                                            N*np.log(np.abs(np.linalg.det(ğšº_t)))

        # Computing texture estimation
        ğ›•_0 =  ğ›•_0 + np.diagonal(ğ—[:,:,t].conj().T@np.linalg.inv(ğšº_0[:,:,t])@ğ—[:,:,t]) / T
        logğ›•_t = logğ›•_t + np.log(np.diagonal(ğ—[:,:,t].conj().T@np.linalg.inv(ğšº_t)@ğ—[:,:,t]))

    # Computing quadratic terms
    log_numerator_quadtratic_terms = T*p*np.sum(np.log(ğ›•_0))
    log_denominator_quadtratic_terms = p*np.sum(logğ›•_t)

    # Final expression of the statistic
    Î» = np.exp(np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms))

    return Î»

##############################################################################
# Some Functions
##############################################################################
def tyler_estimator_covariance_matandtext(ğ—, tol=0.0001, iter_max=20):
    """ A function that computes the Modified Tyler Fixed Point Estimator for 
    covariance matrix estimation under problem MatAndText.
        Inputs:
            * ğ— = a matrix of size p*N*T with each saptial observation along column dimension and time
                observation along third dimension.
            * tol = tolerance for convergence of estimator
            * iter_max = number of maximum iterations
        Outputs:
            * ğšº = the estimate
            * Î´ = the final distance between two iterations
            * iteration = number of iterations til convergence """

    (p, N, T) = ğ—.shape
    Î´ = np.inf # Distance between two iterations
    ğšº = np.eye(p) # Initialise estimate to identity
    iteration = 0

    # Recursive algorithm
    while (Î´>tol) and iteration < iter_max:

        # Compute the textures for each pixel using all the dates avalaibe
        Ï„ = 0
        iğšº = np.linalg.inv(ğšº)
        for t in range(0, T):
            Ï„ = Ï„ + np.diagonal(ğ—[:,:,t].conj().T@iğšº@ğ—[:,:,t])

        # Computing expression of the estimator
        ğšº_new = 0
        for t in range(0, T):
            ğ—_bis = ğ—[:,:,t] / np.sqrt(Ï„)
            ğšº_new = ğšº_new + (p/N) * ğ—_bis@ğ—_bis.conj().T

        # Imposing trace constraint: Tr(ğšº) = p
        ğšº_new = p*ğšº_new/np.trace(ğšº_new)

        # Condition for stopping
        Î´ = np.linalg.norm(ğšº_new - ğšº, 'fro') / np.linalg.norm(ğšº, 'fro')

        # Updating ğšº
        ğšº = ğšº_new
        iteration = iteration + 1

    if iteration == iter_max:
        warnings.warn('Recursive algorithm did not converge')

    return (ğšº, Î´, iteration)


def tyler_estimator_covariance_text(ğ—, tol=0.0001, iter_max=20):
    """ A function that computes the Modified Tyler Fixed Point Estimator for
    covariance matrix estimation under problem TextGen.
        Inputs:
            * ğ— = a matrix of size p*N*T with each saptial observation along column dimension and time
                observation along third dimension.
            * tol = tolerance for convergence of estimator
            * iter_max = number of maximum iterations
        Outputs:
            * ğšº = array of size (p,p,T) to the different estimates
            * ğ›… = the final distance between two iterations for each estimate
            * iteration = number of iterations til convergence """

    (p, N, T) = ğ—.shape
    ğ›… = np.inf*np.ones(T) # Distance between two iterations for each t
    ğšº = np.tile(np.eye(p).reshape(p,p,1), (1,1,T)) # Initialise all estimates to identity
    iteration = 0

    # Recursive algorithm
    while (np.max(ğ›…)>tol) and iteration < iter_max:

        # Compute the textures for each pixel using all the dates avalaibe
        Ï„ = 0
        for t in range(0, T):
            iğšº_t = np.linalg.inv(ğšº[:,:,t])
            Ï„ = Ï„ + np.diagonal(ğ—[:,:,t].conj().T@iğšº_t@ğ—[:,:,t])

        # Computing expression of the estimator
        ğšº_new = np.zeros((p,p,T)).astype(complex)
        for t in range(0, T):
            ğ—_bis = ğ—[:,:,t] / np.sqrt(Ï„)
            ğšº_new[:,:,t] = (T*p/N) * ğ—_bis@ğ—_bis.conj().T

            # Imposing trace constraint: Tr(ğšº) = p
            ğšº_new[:,:,t] = p*ğšº_new[:,:,t]/np.trace(ğšº_new[:,:,t])

            # Condition for stopping
            ğ›…[t] = np.linalg.norm(ğšº_new[:,:,t] - ğšº[:,:,t], 'fro') / \
                     np.linalg.norm(ğšº[:,:,t], 'fro')
        
        # Updating ğšº
        ğšº = ğšº_new
        iteration = iteration + 1

    if iteration == iter_max:
        warnings.warn('Recursive algorithm did not converge')

    return (ğšº, ğ›…, iteration)