##############################################################################
# Functions used to detect a change in the parameters of a SIRV distribution
# Authored by Ammar Mian, 28/09/2018
# e-mail: ammar.mian@centralesupelec.fr
##############################################################################
# Copyright 2018 @CentraleSupelec
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##############################################################################
import numpy as np
import scipy as sp
import warnings
from generic_functions import *

##############################################################################
# Gaussian Statistics
##############################################################################
def covariance_equality_glrt_gaussian_statistic(, args=None):
    """ GLRT statistic for detecting a change of covariance matrix in a multivariate Gaussian Time Series.
        At each time, Ni.i.d samples are available. A description of the statistic can be found in:
        D. Ciuonzo, V. Carotenuto and A. De Maio, 
        "On Multiple Covariance Equality Testing with Application to SAR Change Detection," 
        in IEEE Transactions on Signal Processing, vol. 65, no. 19, pp. 5078-5091, 1 Oct.1, 2017.
        doi: 10.1109/TSP.2017.2712124
        Inputs:
            *  = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
            * args = None
        Outputs:
            * the GLRT statistic given the observations in input"""

    (p, N, T) = .shape
    S = 0
    logDenominator = 0
    for t in range(0, T):
        St = SCM([:, :, t])
        logDenominator = logDenominator + N * np.log(np.abs(np.linalg.det(St)))
        S = S + St / T
    logNumerator = N * T * np.log(np.abs(np.linalg.det(S)))
    if args is not None:
        if args=='log':
            return np.real(logNumerator - logDenominator)
    return np.exp(np.real(logNumerator - logDenominator))


def covariance_equality_t1_gaussian_statistic(, args=None):
    """ t1 statistic for detecting a change of covariance matrix in a multivariate Gaussian Time Series.
        At each time, Ni.i.d samples are available. A description of the statistic can be found in:
        D. Ciuonzo, V. Carotenuto and A. De Maio, 
        "On Multiple Covariance Equality Testing with Application to SAR Change Detection," 
        in IEEE Transactions on Signal Processing, vol. 65, no. 19, pp. 5078-5091, 1 Oct.1, 2017.
        doi: 10.1109/TSP.2017.2712124
        Inputs:
            *  = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
        Outputs:
            * the t1 statistic given the observations in input"""

    (N, K, M) = .shape

    Sigma_10 = SCM(.reshape((N, K*M)))
    iSigma_10 = np.linalg.inv(Sigma_10)
    t1 = 0
    for t in range(0, M):
        Sigma_m1 = SCM([:, :, t])
        S = (iSigma_10 @ Sigma_m1)
        t1 = t1 + np.trace( S @ S )/M;

    if args is not None:
        if args=='log':
            return np.log(np.real(t1))
    return np.real(t1)


def covariance_equality_Wald_gaussian_statistic(, args=None):
    """ Wald statistic for detecting a change of covariance matrix in a multivariate Gaussian Time Series.
        At each time, Ni.i.d samples are available. A description of the statistic can be found in:
        D. Ciuonzo, V. Carotenuto and A. De Maio, 
        "On Multiple Covariance Equality Testing with Application to SAR Change Detection," 
        in IEEE Transactions on Signal Processing, vol. 65, no. 19, pp. 5078-5091, 1 Oct.1, 2017.
        doi: 10.1109/TSP.2017.2712124
        Inputs:
            *  = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
        Outputs:
            * the Wald statistic given the observations in input"""

    (N, K, M) = .shape
    L = 0;
    O = 0;
    Q = 0;
    Sigma_11 = SCM([:, :, 0])
    for m in range(0,M):
        Sigma_m1 = SCM([:, :, m])
        iSigma_m1 = np.linalg.inv(Sigma_m1)
        if m != 0:
            S = np.eye(N) - Sigma_11@iSigma_m1
            L = L + K*np.trace(S@S)
            Q = Q + K*(iSigma_m1 - iSigma_m1@Sigma_11@iSigma_m1)
        O = O + K*np.kron(iSigma_m1.T, iSigma_m1)
    
    if args is not None:
        if args=='log':
            return np.real(np.real(L - vec(Q).conj().T @ (np.linalg.inv(O)@vec(Q)))[0,0])
    return np.real(L - vec(Q).conj().T @ (np.linalg.inv(O)@vec(Q)))[0,0]


##############################################################################
# Robust Statistics
##############################################################################
def student_t_shape_statistic_d_known(X, Args):
    """ GLRT test for testing a change in the shape of a multivariate
        Student-t distribution when the degree of freefom is known.
        Inputs:
            * X = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
            * Args = d=degree of freedom and tol, iterMax for Tyler, scale
        Outputs:
            * the statistic given the observations in input"""

    d, tol, iter_max, scale = Args
    (p, N, T) = .shape

    # Estimating _0 using all the observations
    (_0, 未, niter) = student_t_estimator_covariance_mle(.reshape((p,T*N)), d, tol, iter_max)
    i_0 = np.linalg.inv(_0)

    # Some initialisation
    log_numerator_determinant_terms = T*N*np.log(np.abs(np.linalg.det(_0)))
    log_denominator_determinant_terms = 0
    log_0 = 0
    log_t = 0
    # Iterating on each date to compute the needed terms
    for t in range(0,T):
        # Estimating _t
        (_t, 未, iteration) = student_t_estimator_covariance_mle([:,:,t], d, tol, iter_max)

        # Computing determinant add adding it to log_denominator_determinant_terms
        log_denominator_determinant_terms = log_denominator_determinant_terms + \
                                            N*np.log(np.abs(np.linalg.det(_t)))

        # Computing quadratic terms
        log_0 =  log_0 + np.log(d + np.diagonal([:,:,t].conj().T@i_0@[:,:,t]))
        log_t = log_t + np.log(d + np.diagonal([:,:,t].conj().T@np.linalg.inv(_t)@[:,:,t]))

    # Computing quadratic terms
    log_numerator_quadtratic_terms = (d+p)*np.sum(log_0)
    log_denominator_quadtratic_terms = (d+p)*np.sum(log_t)

    # Final expression of the statistic
    if scale=='linear':
        位 = np.exp(np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms))
    else:
        位 = np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms)

    return 位


def scale_and_shape_equality_robust_statistic(, args):
    """ GLRT test for testing a change in the scale or/and shape of 
        a deterministic SIRV model.
        Inputs:
            *  = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
            * args = tol, iter_max for Tyler, scale
        Outputs:
            * the statistic given the observations in input"""

    tol, iter_max, scale = args
    (p, N, T) = .shape

    # Estimating _0 using all the observations
    (_0, 未, niter) = tyler_estimator_covariance_matandtext(, tol, iter_max)
    i_0 = np.linalg.inv(_0)

    # Some initialisation
    log_numerator_determinant_terms = T*N*np.log(np.abs(np.linalg.det(_0)))
    log_denominator_determinant_terms = 0
    _0 = 0
    log_t = 0
    # Iterating on each date to compute the needed terms
    for t in range(0,T):
        # Estimating _t
        (_t, 未, iteration) = tyler_estimator_covariance([:,:,t], tol, iter_max)

        # Computing determinant add adding it to log_denominator_determinant_terms
        log_denominator_determinant_terms = log_denominator_determinant_terms + \
                                            N*np.log(np.abs(np.linalg.det(_t)))

        # Computing texture estimation
        _0 =  _0 + np.diagonal([:,:,t].conj().T@i_0@[:,:,t]) / T
        log_t = log_t + np.log(np.diagonal([:,:,t].conj().T@np.linalg.inv(_t)@[:,:,t]))

    # Computing quadratic terms
    log_numerator_quadtratic_terms = T*p*np.sum(np.log(_0))
    log_denominator_quadtratic_terms = p*np.sum(log_t)

    # Final expression of the statistic
    if scale=='linear':
        位 = np.exp(np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms))
    else:
        位 = np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms)

    return 位

def shape_equality_robust_statistic(, args):
    """ GLRT test for testing a change in the shape of 
        a deterministic SIRV model.
        Inputs:
            *  = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
            * args = tol, iter_max for Tyler, scale
        Outputs:
            * the statistic given the observations in input"""

    tol, iter_max, scale = args
    (p, N, T) = .shape

    # Estimating _0 using all the observations
    (_0, 未, niter) = tyler_estimator_covariance(.reshape((p,T*N)), tol, iter_max)
    i_0 = np.linalg.inv(_0)

    # Some initialisation
    log_numerator_determinant_terms = T*N*np.log(np.abs(np.linalg.det(_0)))
    log_denominator_determinant_terms = 0
    log_0 = 0
    log_t = 0
    # Iterating on each date to compute the needed terms
    for t in range(0,T):
        # Estimating _t
        (_t, 未, iteration) = tyler_estimator_covariance([:,:,t], tol, iter_max)

        # Computing determinant add adding it to log_denominator_determinant_terms
        log_denominator_determinant_terms = log_denominator_determinant_terms + \
                                            N*np.log(np.abs(np.linalg.det(_t)))

        # Computing texture estimation
        log_0 =  log_0 + np.log(np.diagonal([:,:,t].conj().T@i_0@[:,:,t]))
        log_t = log_t + np.log(np.diagonal([:,:,t].conj().T@np.linalg.inv(_t)@[:,:,t]))

    # Computing quadratic terms
    log_numerator_quadtratic_terms = p*np.sum(log_0)
    log_denominator_quadtratic_terms = p*np.sum(log_t)

    # Final expression of the statistic
    if scale=='linear':
        位 = np.exp(np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms))
    else:
        位 = np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms)

    return 位


def scale_equality_robust_statistic(, args):
    """ GLRT test for testing a change in the scale of 
        a deterministic SIRV model.
        Inputs:
            *  = a (p, N, T) numpy array with:
                * p = dimension of vectors
                * N = number of Samples at each date
                * T = length of time series
            * args = tol, iter_max for Tyler, scale
        Outputs:
            * the statistic given the observations in input"""

    tol, iter_max, scale = args
    (p, N, T) = .shape

    # Estimating _t under H0 regime using all the observations
    (_0, , niter) = tyler_estimator_covariance_text(, tol, iter_max)

    # Some initialisation
    log_numerator_determinant_terms = 0
    log_denominator_determinant_terms = 0
    _0 = 0
    log_t = 0
    # Iterating on each date to compute the needed terms
    for t in range(0,T):

        # Estimating _t under H1 regime
        (_t, 未, iteration) = tyler_estimator_covariance([:,:,t], tol, iter_max)

        # Computing determinant add adding it to log_numerator_determinant_terms
        log_numerator_determinant_terms = log_numerator_determinant_terms + \
                                        N*np.log(np.abs(np.linalg.det(_0[:,:,t])))

        # Computing determinant add adding it to log_denominator_determinant_terms
        log_denominator_determinant_terms = log_denominator_determinant_terms + \
                                            N*np.log(np.abs(np.linalg.det(_t)))

        # Computing texture estimation
        _0 =  _0 + np.diagonal([:,:,t].conj().T@np.linalg.inv(_0[:,:,t])@[:,:,t]) / T
        log_t = log_t + np.log(np.diagonal([:,:,t].conj().T@np.linalg.inv(_t)@[:,:,t]))

    # Computing quadratic terms
    log_numerator_quadtratic_terms = T*p*np.sum(np.log(_0))
    log_denominator_quadtratic_terms = p*np.sum(log_t)

    # Final expression of the statistic
    if scale=='linear':
        位 = np.exp(np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms))
    else:
        位 = np.real(log_numerator_determinant_terms - log_denominator_determinant_terms + \
        log_numerator_quadtratic_terms - log_denominator_quadtratic_terms)

    return 位

##############################################################################
# Some Functions
##############################################################################
def tyler_estimator_covariance_matandtext(, tol=0.0001, iter_max=20):
    """ A function that computes the Modified Tyler Fixed Point Estimator for 
    covariance matrix estimation under problem MatAndText.
        Inputs:
            *  = a matrix of size p*N*T with each saptial observation along column dimension and time
                observation along third dimension.
            * tol = tolerance for convergence of estimator
            * iter_max = number of maximum iterations
        Outputs:
            *  = the estimate
            * 未 = the final distance between two iterations
            * iteration = number of iterations til convergence """

    (p, N, T) = .shape
    未 = np.inf # Distance between two iterations
     = np.eye(p) # Initialise estimate to identity
    iteration = 0

    # Recursive algorithm
    while (未>tol) and iteration < iter_max:

        # Compute the textures for each pixel using all the dates avalaibe
         = 0
        i = np.linalg.inv()
        for t in range(0, T):
             =  + np.diagonal([:,:,t].conj().T@i@[:,:,t])

        # Computing expression of the estimator
        _new = 0
        for t in range(0, T):
            _bis = [:,:,t] / np.sqrt()
            _new = _new + (p/N) * _bis@_bis.conj().T

        # Imposing trace constraint: Tr() = p
        _new = p*_new/np.trace(_new)

        # Condition for stopping
        未 = np.linalg.norm(_new - , 'fro') / np.linalg.norm(, 'fro')

        # Updating 
         = _new
        iteration = iteration + 1

    if iteration == iter_max:
        warnings.warn('Recursive algorithm did not converge')

    return (, 未, iteration)


def tyler_estimator_covariance_text(, tol=0.0001, iter_max=20):
    """ A function that computes the Modified Tyler Fixed Point Estimator for
    covariance matrix estimation under problem TextGen.
        Inputs:
            *  = a matrix of size p*N*T with each saptial observation along column dimension and time
                observation along third dimension.
            * tol = tolerance for convergence of estimator
            * iter_max = number of maximum iterations
        Outputs:
            *  = array of size (p,p,T) to the different estimates
            *  = the final distance between two iterations for each estimate
            * iteration = number of iterations til convergence """

    (p, N, T) = .shape
     = np.inf*np.ones(T) # Distance between two iterations for each t
     = np.tile(np.eye(p).reshape(p,p,1), (1,1,T)) # Initialise all estimates to identity
    iteration = 0

    # Recursive algorithm
    while (np.max()>tol) and iteration < iter_max:

        # Compute the textures for each pixel using all the dates avalaibe
         = 0
        for t in range(0, T):
            i_t = np.linalg.inv([:,:,t])
             =  + np.diagonal([:,:,t].conj().T@i_t@[:,:,t])

        # Computing expression of the estimator
        _new = np.zeros((p,p,T)).astype(complex)
        for t in range(0, T):
            _bis = [:,:,t] / np.sqrt()
            _new[:,:,t] = (T*p/N) * _bis@_bis.conj().T

            # Imposing trace constraint: Tr() = p
            _new[:,:,t] = p*_new[:,:,t]/np.trace(_new[:,:,t])

            # Condition for stopping
            [t] = np.linalg.norm(_new[:,:,t] - [:,:,t], 'fro') / \
                     np.linalg.norm([:,:,t], 'fro')
        
        # Updating 
         = _new
        iteration = iteration + 1

    if iteration == iter_max:
        warnings.warn('Recursive algorithm did not converge')

    return (, , iteration)